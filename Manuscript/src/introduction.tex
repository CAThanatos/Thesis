\chapter{Introduction}

\minitoc[n] % minitoc without title

\section{The Evolution of Cooperation}

  \subsection{Cooperative Behaviours and their Importance in Evolutionary History}

    Among all of the social interactions present in nature, cooperation is the one that seems to be the most recurrent in any level of organisms' complexity. This is also a behaviour whose displays and pratical occurences are as diverse as useful for many different species. A most basic definition of cooperation is that it is a behaviour where an \emph{actor} (the individual who initiate the behaviour) will behave in such a way that is beneficial to a \emph{recipient} (the other individual with the behaviour)~\cite{West2007a}. In particular, this behaviour will most often be costly for the actor. Obviously, in most acts of cooperation more than two individuals are directly concerned. And it can even actually be difficult to clearly define the actors and the recipients.

    But cooperation can be found at nearly any level of living complexity (TODO: PHRASING BOF). For example, even unicellular organisms such as bacteria are known to frequently act in a cooperative manner. Mostly based on secreting and using by-products, these organisms are capable of sharing and communication~\cite{West2007b}. A comparison is even often created between the way those bacteria exchange those by-product benefits to \emph{public goods} situations. These are are well known in the study of cooperative dilemma and in economy in particular. Moreover, it could be argued that the way genes interact together inside of a genome could fall under the umbrella of cooperation. Thus, even if in this case it could be debatable wether those are considered living organisms, it is clear that cooperation can be found at levels (TODO: bof le level) lower than could be imagined. Finally, multicellularity is a perfect example of high cooperation between numerous different organisms. Single prokaryotic organisms managed at some point to gather and incorporate as mitochondries what are now eukaryotic cells to form these complex multicellular organisms. This is considered no less as one of the major transitions in evolution~\cite{Szathmary1995}.

    If we focus our attention a little higher to organisms of a bigger size, an example which quickly comes in mind is eusociality~\cite{Wilson1990}. Of which the more obvious (but not only) representatives are insects like ants or termites. (TODO : def eusociality ?) These individuals have evolved one of the highest levels of sociality which implies that they constantly demonstrate very high levels of cooperation. Examples are numerous but among them individuals take cooperatively care of youngs which are not of their own (as they often are incapable of reproductive capabilities). Moreoever, they often display strong examples of division of labour, where individuals are able to divide between different to roles to achieve one or more complex tasks. In particular, in most eusocial organisms, this division of labour is permanent, leading to strong morphological differences between individuals of different behavioural groups (TODO : ref needed). Finally, the fact that most of the individuals in eusocial societies are denied reproduction is also an extreme form of cooperation.

    % TODO : mentionner les herds, flocks et schools ? En gros comportements collectifs
    % A lot of collective behaviours of larger animals can also be deemed cooperative. This is true even for animals who are not known to live in complex social structures. For example, the behaviours of fishes

    Again if we increase the scope and size of our study, we can find other examples of cooperations. Indeed among, the existence of strong sociality (what is called presociality) in a lot of animals comes with astonishing displays of cooperation (TODO : ref needed). These acts of cooperation may not be of less interest that those of a eusocial animals but they are closer to our understanding as human beings. Some mammal predators are capable of displaying amazing (TODO : bof) capacities for collective hunting, among them the obvious examples of wolves and lions (TODO : ref needed). But other more easily forgotten predators like hyenas (TD : RN) are known to rely on signaling and communication to create a complex coordination between up to a dozen of different members (TD : ouais bon vérifier le nombre quand même). The behaviours of those predators could easily be considered as strategy by a human observer. But even when hunting is not involved, cooperation is strong in these social animals. In a lot of species, individuals can act as lookout to watch for nearby predators. Most often, these members take the risk of attracting those same predators when they warn their companions, something which has been puzzling for a long time. Finally, even if the level of cooperation is not as strong as that of eusocial animals, we can find copious examples of cooperations inside these societies. Some adults take care of youngs which are not their own (TD:RN) which is known as allo-parenting or individuals partake in social bonding activities (like social grooming).

    What can be more stunning is to find cooperation between even members of different species. Again, examples are numerous. Again, sometimes this cooperation happens on a very small scale. In particular, the gut flora of some animals (including human beings) is constituted of bactera that help us process food. On a bigger scale we can think of cleaning fishes or the fact that some species of killer whales help human catch fishes, their benefit being they can prey on the birds attracted by the by-products of human fishing (TD:RN). Finally, domestication is another powerful example of interspecific cooperation. Interestingly, domestication can be found in other animals than human (e.g. ants and aphids TD:RN).

    In conclusion, in nearly every different levels of complexity in the living world, we can find displays of cooperation. More importantly, cooperation is not only present but also seems to be one of the factors for every major transitions in evolution~\cite{Szathmary1995}. Yet its evolution can be hard to explain at first glance. Indeed, according to darwinian evolution, a behaviour should be selected only if it benefits the individual who displays it (TD:RN ? mon poto Darwin ?). This obviously seems to contradict the very definition of cooperation. This is thus a problem which has (and still is) of major interest for evolutionary biology.


    % TODO : Darwing parlait déjà du problème de la coopération je crois non ?
    % TODO : caser les humains dans le tas encore ? C'est du presocial mais j'aimerais bien dire un truc sur "la coop c'est à la base de la structure sociale et bla bla bla"

  \subsection{Altruism and Indirect Fitness Benefits}

    One particular type of cooperative act which has garnered a lot of attention is the evolution of \emph{altruism}. We consider a behaviour to be altruistic when the actor pays a cost in an action benefitting another individual~\cite{Hamilton1964, West2007a}. We have to also keep in mind than when the terms "costs" and "benefits" refer to the fitness of the individual (i.e. the number of this individual's offsprings). This brings the problem that some cooperative actions deemed altruistic in the short term could reveal to be simply beneficial to the actor in the long time. This sparked major debates on the very definition of altruism which we will not talk about in details in this manuscript (TD:RN for comprehensive review). We will simply here settled for the definition mostly admitted today of considering the costs and benefits on the lifetime fitness of the individuals~\cite{West2007a, Lehmann2006}.

    The main problem posed by the evolution of altruism is its stability against the invasion of cheaters. If we consider a population of individuals who can either be cooperators or cheaters, it is easy to see that the cheaters will quickly invade the population. Indeed, in a theoretical point of view, cheaters are those who will selfishly benefit from the cooperative behaviour of the cooperators without ever paying the cost of cooperation. In consequence, their fitness will be higher than that of cooperators and cheaters will be able to quickly invade the population. This leads to a population entirely constituted of cheaters, although the mean fitness may be smaller than that of a population constituted of cooperators.

    This has led to numerous research on the evolution of altruism. The most well-known explanation of the evolution of altruism is \emph{kin selection} and \emph{indirect fitness}~\cite{Hamilton1964}. These two concepts mean that the evolution of altruism can be favored between closely related individuals. In a sense, by helping a genetically similar individual increase its fitness, an individual can \emph{indirectly} pass its genes to the next generation. This concept is nicely summarized by the now popular \emph{Hamilton's rule}~\cite{Hamilton1964} which states that altruism should be selected if:

    \[br > c\],

    where $b$ and $c$ are respectively the benefits and costs of the cooperative behaviour and $r$ the genetic relatedness of the two individuals (i.e. how genetically similar are the two individuals in comparison to the rest of the population). To put it more simply, an altruistic trait can be selected if the benefits of these traits weighted by the relatedness to the individuals outweigh the cost of cooperation.

    The problem is that there needs to be a mechanism which ensure the relatedness of individuals. Several mechanisms have been thought and proved to allow kin selection to happen in nature. First, \emph{kin discrimination} can be sufficient to recognize genetically similar partner. Through the use of either environmental or genetic cues~\cite{Grafen1990}. Numerous examples of kin discrimination have been found which support this mechanisms (TD:prendre les exemples de West et al. ?). Then, some argue that limited dispersal can be also responsible for the appearance of kin selection~\cite{Hamilton1972, Griffin2003}. Under limited dispersal, relatives will tend to keep together close to one another. What this means is that altruism directed to any neighbours can evolve because of the strong relatedness to those close to the individual. Thus, even without any particular recognition mechanisms, it is possible to ensure kin selection. Lastly while occurences are rare, we need to mention the green beard mechanism~\cite{Hamilton1964, Lehmann2006}. Rather than focusing on the mean similarity between the individuals' genotypes, this mechanism relates to relatedness on a particular loci in the genotype. Behind this term is the idea of a particular gene which would be tied to that for cooperation and help recognize cooperator (e.g. thanks to a particular phenotypical trait) and prompt individuals to cooperate with those with the same trait.

    Finally, some have argued that group selection could explain the evolution of altruism. This particular theory sparked passionate debates between those in favor of group selection and those in favor of kin selection. In summary, supporters of group selection argue that selection can occur at the level of the groups of individuals. This means that while a population of altruistic cooperators can indeed easily be invaded by cheaters, a group of cheaters will perform on average worse than a group of cooperator. Thus a group of cheaters can go extinct because of those selfish behaviours or be outcompeted by cooperators. Since then, it has been shown than kin selection and group selection tend to relate to the same mathematical relations~\cite{Hamilton1975, VanBaalen1998, Gardner2007}.


  \subsection{Direct Fitness Benefits and Mutualism}

    But most of the cooperative actions do not fall under the umbrella of the indirect fitness benefits. In fact cooperation can also be directly beneficial to the actor~\cite{Leimar2010}. In this case, both the actor and the recipient benefit from cooperation and we then say that the behaviour is mutually beneficial~\cite{West2007a}. There can sometimes be confusion in the litterature between some of the more important terms here. In consequence, it is important to clearly state what we are refering to. For example, some have considered cooperation to only concern mutually beneficial behaviours~\cite{Trivers1985, Lehmann2006}. Here we consider the broader definition where cooperation includes both altruistic and mutualistic actions~\cite{West2007a}. There seems also to be a great deal of confusion around the term \emph{mutualism}. While some (TD:RN) use it to describe mutually beneficial actions or even cooperation as a whole (as previously explained), it is also used to refer to interspecific mutualism. As in our case we are interested in intraspecific cooperation we will tend to follow the advice of West et al.~\cite{West2007} and stick to "mutually beneficial" throughout this manuscript.

    These mutually beneficials actions can sometimes be enforced by in a lot of different manners. For example, cooperation can be enforced through punishment. This is something that is common in humans~\cite{Fehr2002} but also in a lot of different social animals. Hyenas for example enforce the cooperation inside the group through exclusive reproduction. The dominant female in the group will attack most of the lower ranking females or their cubs to ensure that her offsprings (and those of a few other high ranking females) are the only youngs in the groupe. This way, they enforce cooperative care (alloparenting) of her youngs and thus increase their survival chances. Another way to enforce cooperation is in reciprocal interactions. Individuals will tend to help those who have helped them in the past and thus provide mutual (albeit delayed) benefits. This particular case of direct benefits was coined as reciprocity~\cite{Trivers1971, Lehmann2006}.

    % TODO: Dire que Trivers parlait d'altruistic reciprocity ou on s'en balance ?

    But what we are interested in here is the case where cooperation between individuals is not enforced. Rather, all individuals have a shared interest in cooperating. For example, a large group of individuals can entail higher chance of survival (against both the environment and predators) and an increase in the benefits from foraging or hunting. This leads individuals to have a mutual benefit in creating groups and societies. It could be (and has been) argued that those cooperative behaviours from which all individuals mutually benefit without enforcement are trivial. For example, in comparison to altruism where the stability of cooperation is constantly threatened by the invasion of mutants, this is not the case when every individuals directly benefit from cooperating. While this may be true, this does not answer the question of \emph{how these cooperative behaviours could evolve in the first place}.

    More precisely, our question is similar to what Calcott~\cite{Calcott2007a} talked about. While the problem of the stability of altruism concerns how to \emph{distribute benefits}, mutually beneficial cooperation poses the problem of how to \emph{generate benefits}. When we are focusing on the problem of distribution of benefits and cooperation's stability, we are mainly interested in \emph{ultimate causation}. What this means is that we tend to abstract from the practical interactions that take place during cooperative actions. This absraction is as useful as necessary to study the key factors that influence the stability of cooperation. We thus study what mechanisms could impact the way benefits are distributed (e.g. indirect benefits, punishment) and what are the consequences on cooperation (i.e. how stable cooperation is against the invasion of the cheater). However, this also means that proximate causation~\cite{Tinbergen1963, West2007} is left ouf from these sort of models. Mainly, the way cooperative behaviours can be bootsrapped (i.e. generation of benefits) and lead to successful cooperation is mostly ignored.

    In this manuscript, we thus want to study the influence of this proximate causation on the evolution of mutually beneficial cooperation. This means that we are more interested in the qualitative study of cooperative behaviours than in their stability. In particular we take the example of collective hunting (TD:RN on collective hunting ?). This means that a group of individuals can share the benefit of a successful hunt, thus belonging to the scope of mutualistic interaction. In particular, the evolution of such mutualistic behaviour requires that several individuals coordinate~\cite{Alvard2001, Alvard2003, Drea2009, Leimar2003} their actions so that they can successfully hunt together (and thus generate benefits). This means that have all have to both evolve a cooperative trait and the capacity to coordinate together. This leads to what we can call a \emph{chicken and egg dilemma}. More precisely, for cooperation to be selected it needs to beneficial; but for this collective action to be beneficial, all individuals must cooperate and thus have already evolve a cooperative trait.

    Given the context of the evolution of coordination, we can understand that taking into account the practical mechanics of behaviour can strongly impact the evolution of cooperation. Too often, we tend to consider that the cooperative can simply evolve so that we can focus on how to maintain them: the behaviours are simply a black box. Here we want to see how to evolve them and what is their influence on the ultimality of cooperation.

    % TODO: Besoin de faire ressortir plus clairement la problématique ?



\section{Model and Method}

  Now that we have properly introduced the global question asked in this manuscript, we are interested in presenting the methods with which our study has been conducted.
  
  \subsection{Game Theory and the Stag Hunt}

    As briefly explained previously, it is common to use abstract models to study the evolution of cooperation. Those models are advantageous in considering general mechanisms and capturing the relations between key factors. From purely computational models to spatial simulations, a considerable toolbox of models has been expanded during the past decades in order to increase our understanding of the evolution of cooperation. A more extensive review of models used for the evolution of cooperation will be provided in Chapter~\ref{chapter:model}.

    Among all these types of models, there is a particulary famous brand of models for cooperation which are game theoretical models. The basic idea is that each theoretical is supposed to represent a particular aspect of a cooperation problem between several (but most often two) players. Each game is provided with a \emph{payoff matrix} whose goal is to indicate, given the strategy of every player, what is the expected reward for each player. This way, the payoff matrix is used to accurately and wholly describe the specificity of the game. These types of model are obviously also very famous in economy and some of them, like the \emph{Prisoner's Dilemma}, are even popular outside the scientific community.

    In the case of coordination games, the classical game theoretical model is called the \emph{Stag Hunt}~\cite{Skyrms2004}. Created by Jean-Jacques Rousseau and popularized by Brian Skyrms, this game follows a simple story (TODO: figure Stag Hunt). Two hunters have the choice of either hunting a hare or a stag. Getting a hare is easy for any of the hunters and in such availability that we can consider that hunting a hare has no influence on the other hunter's strategy. However, a stag represents a much harder prey to hunt so that both hunters need to cooperate if they want to reap the benefits of going for the stag. Finally, a stag is obviously much more rewarding than a hare. Thus there is a real incentive to cooperate but also a risk of trying to cooperate alone and thus being at a disadvantage w.r.t. relative payoff. As for most game theoretical models, the exact payoffs are of no particular interest as long as the order between each situation is respected. In the case of stag hunt, the order for each hunter is as follows: successful cooperation on stag, hunting hare (whatever the partner's strategy) and failed cooperation.

    The particularity of this game is that there are two evolutionary stable Nash equilibria (TD:RN ?), which means that both individuals hunting hare and both individuals hunting stag are stable. More precisely, this implies that, in comparison to the Prisoner's Dilemma, when the cooperative equilibrium is evolved (hunting stag), its stability is not threatened by the invasion of "defector" (hare hunters). Consequently, in this game we are interested in the bootstrap of the cooperative strategy.

    % TODO: Est-ce que du coup le SH ne s'occupe pas déjà à la base que de la génération de bénéfices ?

    But as previously said, the abstraction created by these theoretical models means that we do not study how benefits are generated. Calcott actually cited the stag hunt as an example of cooperative games where we lacked understanding of the manner in which the coordinative abilities of the individuals can appear~\cite{Calcott2007a}. In particular, in the existing litterature about the stag hunt (TD:RN ?), we tend to assume that the evolution of cooperation is coupled with that of coordination. In reality, cooperation cannot be successful unless coordination has already evolved.

    That is why the goal of our model is to take inspiration from the game theoretical framework of the stag hunt to shed a light on this particular problem. This means that we need to use a method which allows for the modeling of those proximate causes. To that end, we chose to use \emph{Evolutionary Robotics}.
    % Dire que ça sera un peu mieux justifié au début du chapitre 1


  \subsection{Evolutionary Robotics}

    Evolutionary robotics is a method based on designing robots in a manner inspired by nature. Using the evolution's principles of \emph{selection} and \emph{variation} as an engineering process is not new. The whole field of evolutionary computing was created on this idea and still offers promising success in optimization problems where more classical methods fail~\cite{Holland1975, Goldberg1989, Eiben2003}. Evolutionary robotics use the same principles to take on the complex task of designing part or all of a complete robot: sensors, morphology and control~\cite{Nolfi2000, Doncieux2015a}. Please keep in mind that when the term "robot" is mentionned here, it can either refer to a physical or simulated robot unless specified.

    % TODO: Dire que l'EC c'est cool pour les black box trucs ?

    In particular, an evolutionary robotics design is based on an evolutionary algorithm whose goal is to evolve a population of artificial genotypes according to a fitness function. While the actual format of the genotype is of no particular interest here, it is however most often randomly generated. This genotype is then translated into a phenotype which will guide the robot's morphology and/or control. Again, the process of translating the genotype to phenotype as well as the actual phenotype can both be very different from one model to the other. On that matter, one must choose what best fits his needs. The important point is that this is this phenotype which is then be evaluated. To that end, the robot is put in the environment where we want it to evolve for some time. 
    
    In the more classical models, a fitness function is used to compute a fitness score from the behaviour of the robot in its environment. It is interesting to note that in thoses instances of evolutionary algorithm, fitness is then used to guide the evolution process. This is obviously contrary to the "real" definition of fitness in evolutionary biology: an a posteriori observation of the capacity to generate offsprings. While this not our subject of interest here, it is interesting to know that a few works in evolutionary robotics have been interested in this more "realistic" approach to evolution. In what's called environment-driven evolutionary robotics, evolution is thus drived by the capacity to survive and generate offsprings rather than by a fitness score~\cite{Ray1991, Bianco2004, Bredeche2010}.

    When all genotypes in the population have been evaluated, the fitness score is then used to select which one will be able to produce offsprings for the next generation. Variation is then finally applied on these offsprings to create the population of the next generation. This variation can consist in mutations on part of the genotype and/or crossover between several (two most probably) genotypes. Then a new generation can take place and the evolution process can be continued as long as needs be.

    Given the problem studied in this manuscript, evolutionary robotics is interesting both as a model and design tool. The fact that what is evaluated is the phenotype of the robot gives the possibility to really observe and study the behaviours evolved. More importantly, this is the interactions between the robot's phenotype and its environment that are really evaluated here. This means that we are able to really look at the coordinative behaviours evolve in a qualitative sense. The evolution of these behaviours can be directly influenced which implies that their implact on the evolution of cooperation can be thoroughly studied: the mechanics of behaviours are not just a black box.

    % 3 - Qu'est-ce que ça apporte (geno - pheno, comportements qui peut être observed, environement, évolution etc...)
        % -> Garder pour Chap. 2



  \subsection{Setting} % TODO: bof

    Now that we have presented both the game theoretical paradigm we take inspiration from and the artificial evolution method, we can finally describe our experimental setting. Please note that, as they may change depending on the experiment, some of the exact parameter values are not specified in this section.

    \subsubsection{Robot model.} We want to study the evolution of simple simulated robotic agents. Those are agents are capable of movement thanks to two independant wheels and are equiped with a collection of sensors. Those sensors are of two types: $12$ \emph{proximity sensors} and a $90$ degrees front {camera}. On the one hand, the proximity sensors are equally distributed all around the robot's body and inform the agent about the proximity of any obstacles nearby (i.e. in a radius which equals twice the body's diameter). On the other hand, the camera cannot recognize the obstacles but can feed the agent with the type of any objects it sees in the environment (including other agents). More precisely, this camera is composed of $12$ rays with an infinite range equally divided in the camera's angle. When one of these rays "sees" an object, the agent can know the type of this object and its proximity. The robot is thus constituted of simple sensory capabilities. While it can appear strange to have a robot model constituted of two different sensory means, this choice is not innocent. By dividing the sensory capabilities between the proximity sensors and the camera, we are essentially easing the process of evolving two basic capabilities necessary for the robot: obstacles avoidance and objects recognition. This design is not to be considered as a realistic approach to evolution but rather as a way to facilitate the acquisition of basic skills that are of no interest here. Furthermore, while obstacles avoidance is not expected to improve much during evolution, the appearance of cooperative behaviours in comparison should lead to variation on objects recognition.

    \subsubsection{Controler.} The controler of the agent is an artificial neuron network (ANN). While a lot of different types of controlers are used in evolutionary robotics, ANN are widely emploied for their versatility~\cite{Doncieux2015}. The principle behind a very basic neural network is that it is constituted of a layer of input neurons and a layer of output neurons which are connected (sometimes fully) to each other. Each one of the connection has a value, which is called a weight. The value of each output neuron is computed as the sum of the input neurons connected to it weighted by the connection weight. A transfer function can then finally be applied to this output to compute the value. 

    In our case, we use a fully connected multilayer perceptron with one hidden layer. This neural network is composed of two outputs which are used to compute the speed of each of the robot's wheel. The inputs of the network are constituted of all the sensory information of the robot plus a bias neuron whose value is always $1$. This amounts to a total number of $49$ input neurons: $1$ for each proximity sensors, $4$ for each camera ray and $1$ for bias. The information of each camera is encoded by $4$ neurons because we use $3$ bits to encode the type of the object and $1$ last neuron for the proximity of this object. The hidden layer is constituted of $8$ neurons. Finally, the transfer function used in each neuron is a sigmoid and the topology of the ANN is never changed throughout evolution.

    \subsubsection{Environment.} We place two evolved robot in an arena with four solid walls. This arena is filled with randomly positioned objects of different type, where the type can be recognized by the camera. These objects represent the prey that can be hunted by the individuals in a stag hunt type of game. These objects cannot move while the robots can move freely. In order to catch an object, an individual need to move to this object and then stay next to it for a specified amount of time steps ($800$). After this duration, the object is removed from its position and replaced at another random position in the environment; we thus ensure a constant ratio of each type of object. For cooperation to occur, both robots need to be close to the object at the end of this duration. This thus implies that robots need to display actual coordinative behaviours in order to be able to cooperate. This also means that an individual can reap the benefits of cooperation simply by being there at the very last step of the catching period.

    An object is always removed if an individual is next to it after this period of time, regardless of wether it requires cooperation. All that varies are the rewards given to the individuals. Please note that, even in case of cooperation, those rewards are never splitted between the individuals: they are both equally rewarded.

    \subsubsection{Evolutionary algorithm.} The genotype of the individuals is constituted of all of the connection weights of the neural network. Each gene is initially randomized in the interval where it takes its values, i.e. in \([0,1]\). To perform the evolution of these genotypes we use a very classical evolutionary algorithm. At each generation of the algorithm we evaluate each individual of the population in the arena presented before. Its partner is randomly selected in the population. To ensure that each individual encounters a fair sample of the population, each individuals is separatly paired with $5$ different partners. Then a pair of individuals interact in the arena during a number of $20000$ time steps. In order to decrase the effect the stochasticity of the objects' random positioning can have on the performance, each pair plays $5$ different simulations. Thus, each individual plays a total number of $25$ simulations. Fitness is obtained by computing the average reward of the individual in these simulations.

    The individuals are then selected to produce offsprings. Throughout our experiments, we mainly studied two different selection methods: \emph{fitness proportionate} and \emph{elitist}. The former is the more classical one in evolutionary biology because it corresponds to a Wright-Fisher model~\ref{Wright1931} with a constant population size. Under this model, we randomly sample through the population to select a parent to create each offspring that will constitute the population of the next generation. Each individual in the population as a higher probability to be selected if its fitness is higher. Each individual can also be selected several times. The latter selection scheme is also called a \((\mu + \lambda)\) evolution strategy. With this selection method, we always keep the $\mu$ best individuals of each generation for the next generation. Then we add $\lambda$ offsprings to the population of the next generation, where the parents of these offsprings are taken from the $\mu$ best individuals. 

    % Justifier Elitist p/r à Fitprop ici ?

    Whatever the selection strategy, we always create the offspring in the same way. Each offspring is a mutated clone of its parent, where mutation is applied independently on each gene according to a mutation rate. If a gene mutates, mutation is sampled according to a gaussian operator. We thuse use no recombination in any of our experiments.


\section{Evolving Coordination in Evolutionary Robotics}
  
  \subsection{Modelling the Evolution of Cooperation}

  \subsection{Designing Cooperative Robots}
    \begin{itemize}
      \item{Both last subsections are brief introductions to each part of the thesis}
    \end{itemize}
