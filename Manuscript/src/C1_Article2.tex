\chapter{The optimization of collective actions by individual selection}
\label{chapter:C1_article2}

\setcounter{secnumdepth}{0}
\setcounter{minitocdepth}{1}
\minitoc[n] % minitoc without title

In this Chapter, we investigate the influence of the nature of coordination behaviours on the optimization of collective actions. This Chapter is presented as a draft for a journal article which will be submitted before the end of the year.

In the previous Chapter we revealed that the evolution of collective actions was hindered by the evolution of coordination. In particular, we used evolutionary robotics to shed a light on the mechanistic constraints at play in the transition from a solitary to a cooperative equilibrium. Here we are interested in understanding how individual selection can lead to the transition between different collective equilibria.

Collective actions reap their benefits through the interactions of multiple individuals. While they may benefit every individuals in a mutualistic fashion, it is not clear how these collective behaviours are reached. More precisely, because they require the coordination of several individuals, multiple stable equilibria may emerge. But, because benefits are obtained through collective action, a single individual deviating from the evolved equilibrium would not be adaptive. This means that a mutant acting toward a different equilibrium would not be selected, even if the equilibrium may be more advantageous for the group. In consequence, the issue of the optimization of collective actions arises. Namely how it is possible for individual selection to lead to the transition toward an optimal equilibrium when another collective equilibrium already evolved ?

One classical mechanism to solve this issue is that group selection. Because those behaviours are beneficial at the level of the group then this means that they are selected at the same level so the argument goes. However, we want to study how collective behaviours could be optimized by individual selection only. To that end, we choose to model the example of collective hunting. In particular, we use a similar model as the one in Chapter~\ref{chapter:C1_article1}. Namely, individuals are evolved in an environment where they can hunt two differently rewarding types of prey: \emph{boar} and \emph{stag}. Each type of prey corresponds to a different collective equilibrium: suboptimal for the boar and optimal for the stag. Our goal is thus to study the transition from the suboptimal equilibrium (i.e. boar hunting) to the optimal equilibrium (i.e. stag hunting).

We reveal that under simple ecological features where only two prey are present in the environment, the transition to the optimum is impossible. However, under more realistic assumptions where the individuals have to choose between multiple prey, then the optimal equilibrium is evolved in $8$ replications out of $30$. In particular, the individuals now have to coordinate in order to achieve cooperation. This means that they need to react to each other behaviour. From this it stems that they also react to a mutant's behaviour. This in turn may allow the group to reap the benefits of stag hunting. 
However, in the coordination strategy evolved by the individuals, they both choose separately which prey to hunt. We then study how a more asymmetrical coordination strategy could impact the transition to the optimum. To that end, we increase the complexity of the neural networks controlling the individus in order to them to evolve more complex coordination strategies. In this case, we reveal that the transition to the optimum is facilitated as stag hunting evolves in $24$ replications out of $30$. Furthermore, we observe the evolution of a more efficient asymmetrical strategy where the individuals adopt two different roles: the \emph{leader/follower} strategy. In this strategy, only the leader decides on which prey to hunt and the follower goes on the same prey. In consequence, while choosing to cooperatively hunt a stag was previously a collective decision making problem, it is now an individual problem. This means that a mutant leader going for a stag is now sufficient for both individuals to reap the benefits of stag hunting. Moreover, the leader/follower strategy evolved because it was more efficient. Thus we showed that the evolution of an individually adaptive coordination strategy led to the optimization of a collective behaviour.

\clearpage



\section{Abstract}


\section{Introduction}
  Many social traits are adaptive thanks to the emergence of collective features. These cooperative behaviours are individually beneficial through interactions with others during a collective action. For example, individuals who engage in collective hunting may be able to kill bigger or faster prey than what could be done in a solitary fashion. However even when mutually beneficial and thus stable when evolved, explaining the origin of these collective behaviours is not trivial. As they function at the level of the group, it may be difficult to explain how these behaviours could evolve through individual selection.

  In particular, because the benefits of cooperative behaviours are reached through collective actions, it appears that no individual variation may lead to changes in the group's behaviour. More precisely, a single mutant acting toward a different collective goal would not be favored by selection because it could not change the collective behaviour of the group. This is the case even if it may actually be more beneficial for all the individuals to do so. From this it stems that multiple equilibria can appear. In particular, individuals could evolve a suboptimal equilibrium or an optimal one. Therefore, because no individual can benefit by deviating from the equilibrium evolved by the group, this raises the issue of optimizing the collective behaviour. More precisely, how can the optimal equilibrium be reached when a suboptimal equilibrium has already emerged ?

  A popular mechanism to explain the selection of equilibria is that of group selection. Because these collective traits are optimized at the level of the group it seems that only a selective pressure at the same level can enable the optimization social traits. Different groups will reach various collective equilibria and thus benefit differently from the evolved equilibrium. In consequence, groups that evolved more optimal equilibria will be at a selective advantage in comparison to others and thus will outcompete and replace the other groups in the population.

  Here, we want to understand how individual selection can optimize collective actions. To that end, we take the example of collective hunting. Because it is necessary to decide on which prey to hunt, this collective behaviour requires the coordination of several individuals. This implies that a single mutant choosing a different prey than that agreed upon would not benefit from this behaviour. Thus several equilibria can evolve depending on the prey on which the group specialized. Therefore, it appears that no individual mutation can divert the group from a suboptimal equilibrium.

  We model collective hunting in evolutionary robotics~\parencite{Nolfi2000, Doncieux2015}. In particular, we design a setting where two individuals can hunt two different prey: a suboptimal one and an optimal one. For the sake of simplicity we choose to arbitrarily call these two prey respectively boar and stag. The reward from hunting a prey depends on the type of prey hunted and the manner in which it is hunted: solitarily or cooperatively. More precisely, two robotic agents are placed in an arena where they can capture non-moving prey. Both these agents are controlled by neural networks, whose connection weights are evolved (see \emph{Materials and Methods} for further description of the experimental setting). In this context, evolutionary robotics is used because it allows to model and study the individual behaviours resulting from the evolved genotypes. Thus, individuals have to coordinate in order to hunt in a cooperative manner. We design the model so that the individuals have evolved the suboptimal equilibrium and that it is not beneficial for a single individual to switch to a different prey alone. We thus want to study how differences in the coordination strategies evolved impact the transition to the optimal equilibrium.

  In a first analysis, we show that the transition from the suboptimal to the optimal equilibrium is impossible. However, we then reveal that when the individuals are evolved in an environment with more realistic ecological features, it sometimes enables the switch toward the optimal prey. In particular, under these new conditions, it is now necessary for individuals to coordinate to reap the benefits of collective hunting. Because individuals react to each other to coordinate, this means that an individual mutant can indirectly change the collective behaviour by way of phenotypical plasticity. Then in a next experiment, we show that a more efficient coordination strategy impacts the probability to switch between equilibria. More precisely, by increasing the neural plasticity of the individuals they are now able to evolve a more efficient coordination strategy: leader/follower. With this strategy, the individuals adopt different roles where the follower reacts strongly to the behaviour of the leader. We reveal that thanks to such coordination strategy, which is individually adaptive, the transition to the optimal equilibrium is highly facilitated. Finally to further reinforce our claim, we study another coordination strategy that also increases the individuals' efficiency. We observe that similar results are obtained.



\section{Results}
  \subsection{The transition to the optimum is impossible}
    In this first experiment, we are interested in the transition to the optimum strategy in a very simple environment w.r.t. collective hunting. More precisely, individuals are evolved in an environment constituted of only a single prey of each type. Rewards for hunting are summarized in Table~\ref{table:tableRewards}. The agents are initially pre-evolved during $3000$ generations in an environment where hunting stags rewards nothing. We thus ensure that the suboptimal equilibrium (i.e. hunting boars cooperatively) has been evolved. Then the individuals are evolved during $6000$ additional generations where hunting stags is rewarded.

    \begin{table}[ht]
      \centering
        \begin{tabular}{|l|r|c|}
          \hline
          \multicolumn{2}{|l|}{\textbf{Prey}} & \textbf{Food Reward} \\
          \hline
          Boar & \textit{alone} & 50 \\
          \hline
          & \textit{coop.} & 125 \\
          \hline
          Stag & \textit{alone} & 0 \\
          \hline
          & \textit{coop.} & 250 \\
          \hline
        \end{tabular}
        \caption{\textbf{Food Rewards for hunting.}
        Rewards depend on whether the hunt was solitary or cooperative.}
      \label{table:tableRewards}
    \end{table}

    We show in Figure~\ref{fig:figControl}(A) the mean proportion of each type of prey hunted over evolutionary time in $30$ independant replications. Figure~\ref{fig:figControl}(B) shows the proportion of prey hunted at the last generation of evolution in each replication. We observe that during the pre-evolution step, a cooperative strategy was evolved on the boars. However even after this step, there was no transition towards hunting stags. This implies that it is in this case impossible to switch from the suboptimal equilibrium to the optimal equilibrium. 

    %In particular, while cooperation was evolved during the pre-evolution step, no coordination strategy was necessary to cooperate under such ecological conditions. Because there is only one prey of each type, there is no need to react to the other individual in order to collectively decide on which prey to choose.

    \begin{figure}[h]
      \centering
        \includegraphics[width=1\linewidth]{fig/ArticleBio2/Fig1.png}
        \caption{\textbf{Mean proportion of prey hunted cooperatively.}
        \emph{(A)} Mean proportion of boars and stags hunted cooperatively by the best individual in each of the $30$ independant replications. The colored areas around the medians represent the first and third quartiles. The red line represents the separation between the pre-evolution step (when hunting stags rewards nothing) and the rest of the evolution. \emph{(B)} Repartition of the prey hunted at the last generation of evolution by the best individual in each replication. Rewards for a boar are 50 if hunted alone and 125 if hunted cooperatively. A stag hunted alone rewards 0 and 250 if hunted in a cooperative fashion (Table~\ref{table:tableRewards}).}
      \label{fig:figControl}
    \end{figure}

  \subsection{Cooperation can be boostrapped under more realistic environmental features}
    However, it is unrealistic to consider collective hunting only under such extreme ecologicial conditions. In particular, in nature hunters are expected to collectively choose which prey to hunt from multiple similar prey. To that end, individuals are now evolved in an environment constituted of $18$ prey, half of them being boars, the other half being stags. As previously, individuals are first pre-evolved during $3000$ generations in an environment where stags do not reward anything. We then want to study the impact of these new environmental conditions on the transition to the purely collective strategy (i.e stag hunting).

    We show in Figure~\ref{fig:figRecycling}(A) the number of replications out of $30$ where the optimal equilibrium evolved. More precisely, we consider that this equilibrium was achieved when more than \(50\%\) of the prey hunted were stags hunted cooperatively. We present the results from two different settings: the \emph{Control} setting and the \emph{Coordination} setting. The Control setting corresponds to what was presented in the previous Section, where the environment is only constituted of one boar and one stag, to act as comparison with the current results. The Coordination setting corresponds to the setting presented in the last paragraph (i.e. $18$ prey in the environment). We observe that the evolution of cooperation on the stags is facilitated as it evolves in $8$ replications out of $30$. 

    % Additionally, we show in this case (Figure~\ref{fig:figRecycling}(B)) that in every replications where stag hunting evolved, more than \(75\%\) of the stags were hunted cooperatively, which points at a cleary cooperative strategy.

    % Cette derniÃ¨re phrase est moyen utile (et le graph aussi du coup -> mais en fait je parle du graph plus loin donc pourquoi pas)

    \begin{figure}[h]
      \centering
        \includegraphics[width=1\linewidth]{fig/ArticleBio2/Fig2.png}
        \caption{\textbf{Proportion of stag hunting runs and proportion of prey hunted.}
        \emph{(A)} Number of replications (out of a total of $30$) where stag hunting evolved in the \emph{Control} and \emph{Coordination} settings. We consider that stag hunting evolved when more than $50\%$ of the prey hunted were stags hunted cooperatively. In the Control setting, the environment is constituted of one boar and one stag. In comparison, in the Coordination setting, $18$ prey are present in the environment and it is thus necessary to coordinate for cooperation to happen. Rewards for a boar are 50 if hunted alone and 125 if hunted cooperatively. A stag hunted alone rewards 0 and 250 if hunted in a cooperative fashion (Table~\ref{table:tableRewards}). \emph{(B)} Repartition of prey hunted at the last generation of evolution by the best individual in every replications in the Coordination setting. The population for each of the replications was previously evolved in an environment where hunting stags rewards nothing.}
      \label{fig:figRecycling}
    \end{figure}

    A striking difference with the previous experiment is that individuals now evolve a coordination strategy. This behaviour, which we call the \emph{turning} strategy, is shown in Figure~\ref{fig:figTurningBehaviour} (a video of these behaviours is also available in Supplementary Materials). When individuals adopt this behaviour, they constantly turn around one another. This way, they ensure that they keep the other individual in their line of sight. At the same time, they move towards a prey and, thanks to their proximity, when one of them gets on a prey the other can join it quickly. In consequence, they are able to achieve cooperation to solve the issue raised by the necessity to decide on which prey to hunt (Figure~\ref{fig:figRecycling}(B)). More importantly, because the hunters now react to each other, the behaviour of a mutant can affect that of the other individuals. This explains why the transition to the optimal equilibrium was enabled.

    However we can observe several drawbacks from this strategy. All these drawbacks come from the fact that both individuals adopt a symmetrical behaviours. In particular, they both steer towards a desired prey and thus react only weakly to the other individual's behaviour. First, as both individuals can guide the group toward a different prey, this may lead to a situation where it is hard to achieve consensus between them. This can considerably slow them down and thus cause suboptimal performance w.r.t. the number of prey hunted. Then, if prey are close to one another, the fact that both individuals can choose a different prey can lead to non-cooperative hunts. Finally, even when the two hunters are moving to the same prey, their constant turning motion to see the other individual implies that they do not take the most direct course towards the prey. Therefore, the evolution of this symmetrical behaviour leads to less than ideal cooperation.

    \begin{figure}[h]
      \centering
        \includegraphics[width=0.7\linewidth]{fig/ArticleBio2/Fig3.png}
        \caption{\textbf{Display of a turning stategy after an entire simulation.}
        Both individuals adopt a \emph{turning} strategy during a complete simulation. The path of the agents is represented in red and blue, starting from their initial positions (represented by black dots). Each disc represents a prey in the environment. Boars are represented in green and stags in purple. When a prey was killed cooperatively, a red cross (resp. blue) is shown on the prey if the red agent (resp. blue) arrived on this prey first.}
      \label{fig:figTurningBehaviour}
    \end{figure}


  \subsection{A more efficient coordination strategy increases the probability to bootstrap stag hunting}
    In a next experiment, we want to study if the evolution of a different coordination strategy could change the outcome of evolution. More precisely, we are interested in the impact of the evolution of less symmetrical strategy. Namely we want the individuals to adopt different roles. To that end, we increase neural complexity of the individuals by allowing the individuals to co-evolve two neural networks as controllers (see \emph{Materials and Methods} for more precise explanations). Each individual then uses only one of the two neural networks during the entirety of a simulation. Addtionally, both individuals randomly adopt a different neural network. Consequently, each individual has an equal probability to use each of its neural networks (and thus perform both behaviours during the simulations).

    We show in Figure~\ref{fig:figRecyclingLeadership} a comparison of the number of replications (out of $30$ in each setting) where the best individual evolved a cooperative strategy on the stags in different settings. The \emph{Control} and \emph{Coordination} settings are defined as in the previous Section and serve as comparison. In the \emph{Coordination+Duplication} setting, the environment is constituted of $18$ prey as in the \emph{Coordination} setting but the duplication of neural networks can happen. Thus individuals are theoretically able to evolve a leader/follower strategy. We observe that when adding neural plasticity, the transition to the optimum is facilitated as it evolves in $24$ replications out of $30$. More importantly, the proportion of replications where the switch to stag hunt emerged is significantly higher than without duplication. 

    %It is also important to note that another control experiment where no recycling was possible (i.e. no small stags) but where individuals have the possibility to evolve two neural networks was conducted. Results were the same as in the Control setting (results shown in Supplementary Materials).

    \begin{figure}[h]
      \centering
        \includegraphics[width=0.7\linewidth]{fig/ArticleBio2/Fig4.png}
        \caption{\textbf{Proportion of cooperative runs.}
        Number of replications (out of a total of $30$) where stag hunting evolved in the \emph{Control}, \emph{Coordination} and \emph{Coordination+Duplication} settings. We consider that stag hunting evolved when more than $50\%$ of the prey hunted were stags hunted cooperatively. In the Control setting, the environment is constituted of one boar and one stag. In comparison, in the Coordination setting, $18$ prey are present in th environment and it is thus necessary to coordinate for cooperation to happen. Finally, in the Coordination+Duplication setting, the environment is also constituted of $18$ prey but individuals have added neural plasticity which allows them to adopt more complex strategies and in particular a leader/follower strategy. Rewards for a boar are 50 if hunted alone and 125 if hunted cooperatively. A stag hunted alone rewards 0 and 250 if hunted in a cooperative fashion (Table~\ref{table:tableRewards}). The population for each of the replications was previously evolved in an environment where hunting stags rewards nothing.}
      \label{fig:figRecyclingLeadership}
    \end{figure}

    There is a drastic difference between the behaviours evolved with and without two networks. Whereas without the duplication of neural networks we revealed that the individuals adopted a turning behaviour, a \emph{leader/follower} strategy was systematically evolved when duplication happened~\ref{fig:figLeadershipBehaviour}. When agents adopt this strategy, they divide between two very different roles. The \emph{leader} looks for prey, gets on them first and checks but rarely on its partner. In comparison, the \emph{follower} tries to keep the leader in its line of sight at all time and join its partner on a common prey. Therefore, in comparison to the coordination strategy previously presented, the individuals adopt asymmetrical behaviours. 

    % Moreover, we observe that one neural network is indeed evolved for the leader behaviour and the other for the follower behaviour.

    This second strategy is more efficient than the turning strategy w.r.t. rewards obtained (as shown in Figure~\ref{fig:fitnessRecyclingLeadership}, Mann-Whitney U test on the mean reward at last generation, {\em p}-value \textless 0.001). This can be explained by two main factors. Firstly the hunters are faster, as the decision about which prey to hunt is made by only one of the two individuals. Thus they achieve a significantly higher number of prey hunted. Secondly, the asymmetry in the decision making process implies that they are more precise at hunting. Therefore, the proportion of successful cooperative hunts is significantly greater. Consequently, the leader/follower strategy is a collective behaviour that is both more efficient at hunting cooperatively but also leads to a higher probability to bootstrap cooperation on the stags.

    \begin{figure}[h]
      \centering
        \includegraphics[width=0.7\linewidth]{fig/ArticleBio2/Fig5.png}
        \caption{\textbf{Display of a leader/follower stategy after an entire simulation.}
        Both individuals adopt a leader/follower strategy during a complete simulation. The path of the agents is represented in red and blue, starting from their initial positions (represented by black dots). Each disc represents a prey in the environment. Boars are represented in blue and stags in purple. When a prey was killed cooperatively, a red cross (resp. blue) is shown on the prey if the red agent (resp. blue) arrived on this prey first.}
      \label{fig:figLeadershipBehaviour}
    \end{figure}

    \begin{figure}[h]
      \centering
        \includegraphics[width=0.7\linewidth]{fig/ArticleBio2/Fig6.png}
        \caption{\textbf{Mean reward comparison of turning and leader/follower strategies.}
        Mean reward of the best individuals in the $30$ replications over evolutionary time by individuals adopting a turning strategy (evolved in the \emph{Coordination} setting) or a leader/follower strategy (evolved in the \emph{Coordination+Duplication} strategy) during the pre-evolution step. Rewards were 50 for a boar if hunted alone, 125 if hunted cooperatively, 0 for a stag hunted alone and 250 if hunted in a cooperative fashion (Table~\ref{table:tableRewards}).}
      \label{fig:fitnessRecyclingLeadership}
    \end{figure}


  \subsection{Similar results are observed when roles are not set}
    We previously showed that the evolution of a leader/follower strategy leads to a more frequent transition to the optimum than with a less efficient strategy. We claim that our results are caused by the more general factor of the asymmetry in the leader/follower behaviour. Indeed this implies that only one of the two individuals is responsible for the decision making. More precisely, the fact that the two individuals are able to use some asymmetrical cue (i.e. the difference in their neural network) allowed them do decide more efficiently. However, as a hunter chooses which network to use at the start the simulation, this implies that the individuals keep the same role during their life (TODO:bof life). We want to study how removing this constraint could impact the results. To that end, we conducted another experiment where both individuals now begin the simulation with the same neural network. They switch to their second neural network (if a duplication event already occurred) only on a specific event during the simulation. In particular, when one of the hunters gets on a prey, the second hunter switches to its second neural network if possible. This is akin to the first hunter signaling that it found a prey to the latter. When the prey is killed, both hunters switch back to their first neural network.

    As in the previous experiment, we compare a \emph{Control} and \emph{Coordination} setting with the \emph{Coordination+Duplication} setting. Only this time, the choice between which neural network to use is done as explained in the previous paragraph. Results are shown in Figure~\ref{fig:figRecyclingComNN}. We see again that the transition to the equilibrium is highly facilitated in the \emph{Coordination+Duplication} setting as in $23$ out of $30$ replications, there was a transition to the optimal equilibrium. Interestingly, the number of replications where the transition happened is similar to that of the previous experiment. And again, the number of replications where the optimization occurred is significantly higher with neural plasticity than without.

    \begin{figure}[h]
      \centering
        \includegraphics[width=0.7\linewidth]{fig/ArticleBio2/Fig7.png}
        \caption{\textbf{Proportion of cooperative runs.}
        Number of replications (out of a total of $30$) where stag hunting evolved in the \emph{Control}, \emph{Coordination} and \emph{Coordination+Duplication} settings. We consider that stag hunting evolved when more than $50\%$ of the prey hunted were stags hunted cooperatively. In the Control setting, the environment is constituted of one boar and one stag. In comparison, in the Coordination setting, $18$ prey are present in the environment and it is thus necessary to coordinate for cooperation to happen. Finally, in the Coordination+Duplication setting, the environment is also constituted of $18$ prey but individuals have added neural plasticity which allows them to adopt more complex strategies. At a beginning of a simulation, both individuals use the same neural network. A change of network occurs for an individual when the other individual gets on a prey. Rewards for a boar are 50 if hunted alone and 125 if hunted cooperatively. A stag hunted alone rewards 0 and 250 if hunted in a cooperative fashion (Table~\ref{table:tableRewards}). The population for each of the replications was previously evolved in an environment where hunting stags rewards nothing.}
      \label{fig:figRecyclingComNN}
    \end{figure}

    If we look at the behaviours evolved (shown in Supplementary Materials) we see the evolution of another similar asymmetrical behaviour, which we call the \emph{search/join strategy}. More precisely, as long as both individuals use the same neural network, they each look for a prey. However, as soon as one of them finds a prey, the switch in networks for the second individual leads to the adoption of a very different behaviour. Even if the collective behaviour is somewhat different from what could be observed in a leader/follower strategy, this strategy is still more efficient than in the turning strategy (Figure~\ref{fig:fitnessRecyclingComNN}, Mann-Whitney U test on the mean reward at last generation, {\em p}-value \textless 0.001).

    \begin{figure}[h]
      \centering
        \includegraphics[width=0.7\linewidth]{fig/ArticleBio2/Fig8.png}
        \caption{\textbf{Mean reward comparison of turning and search/join strategies.}
        Mean reward of the best individuals in the $30$ replications over evolutionary time by individuals adopting a turning strategy (evolved in the \emph{Coordination} setting) or a search/join strategy (evolved in the \emph{Coordination+Ducpliation} strategy) during the pre-evolution step. Rewards were 50 for a boar if hunted alone, 125 if hunted cooperatively, 0 for a stag hunted alone and 250 if hunted in a cooperative fashion (Table~\ref{table:tableRewards}).}
      \label{fig:fitnessRecyclingComNN}
    \end{figure}  




\section{Discussion}
  Because collective hunting is dependent on the simultaneous actions of several individuals, its optimization is difficult. In particular, when a suboptimal equilibrium has already been evolved, it is not well understood how the group could switch to the optimum through individual adaptation. Here we showed how the nature of coordination strategies could influence this transition. In particular, our simulations in evolutionary robotics revealed that the recycling of a previously evolved coordination strategy could facilite the transition to the optimum. In a simple environment where it was not necessary to coordinate for cooperation to happen, the switch to the optimal equilibrium is impossible. Surprisingly, when hunting cooperatively is more complex, we revealed that the transition to the optimum was possible. In particular, when coordination was needed to cooperate, the transition to stag hunting was enabled in a significant number of simulations ($8$ out of $30$). Indeed, the emergence of stag hunting in our experiment implies that multiple mutations occur during evolution: the capacity to coordinate and the preference to hunt stags. More importantly, both of these mutations are not beneficial on their own which means that they should appear simultaneously. When a successful coordination strategy has already been evolved, the mutational distance is thus decreased. 

  But the nature of the coordination strategy evolved is also of utmost importance. To highlight this point, we increased the complexity of the neural networks controlling the agents. This was done by allowing the random duplication of neural networks during evolution. We then showed that, depending on the way the choice of network is done, the individuals evolve two different strategies: a \emph{leader/follower} strategy and a \emph{search/join} strategy. In both of these strategies, the individuals adopt heterogeneous behaviours. We show that when one of these two strategies is evolved, the probability for the transition to the optimal equilibrium to happen is significantly higher ($24$ and $23$ out of $30$). This high difference can be explained by the asymmetry of both these behaviours. More precisely, the decision making process of choosing the prey on which to cooperate is now one-sided. In the leader/follower strategy, only the leader chooses the prey. In comparison, in the search/join strategy, as soon as one of the two individuals gets on a prey, the other tries immediatly to join it. This means that, in both cases, the hunting preference of the follower (whether its role is temporary or not) does not matter. More precisely, the follower only reacts to the leader. This implies that a change in the leader behaviour indirectly changes that of the follower. Consequently, a modification in the hunting preference of the individual choosing the prey is sufficient for cooperation on the stag to occur. The mutational distance is thus decreased by both the recycling \emph{and} the evolution of an asymmetrical coordination strategy. From this, it stems that the probability to bootstrap stag hunting is higher. 

  More generally, what we reveal through these results is something more critical about the optimization of collective traits. Thanks to the asymmetry of both of these complex strategies, coordination switched from a collective decision making problem to an individual decision making problem. Whereas the transition to the optimum was previously a collective problem, it now depends on the mutations of a single individual. More importantly, both of these strategies were more efficient than the turning strategy evolved without multiple neural networks. Moreover, we did not enforce the evolution of these particular strategies. They simply evolved because their efficiency made them more beneficial \emph{individually}. Thus strategies which were individually adaptive led to the adaptation of a collective trait. No group level mechanisms were necessary for group adaptation to take place. This suggests that multiple group behaviours may also be explained by such mechanisms, opening a wide range of interesting perspectives on this matter.


\section{Materials and Methods}
\label{sec:matandmet}
  \subsection*{Experimental Setup}
    The environment is constituted of a $800$ by $800$ units arena with four solid walls. We place a collection of circular agents (with a diameter of $20$ units) in this arena. The agents are divided between two categories: predators and prey. Predators can move freely in the environment according to the inputs of their sensors which are comprised of several proximity sensors and a camera. Proximity sensors are evenly distributed around the robotic agent's body and have a range of twice the body's diameter. Each of these proximity sensors informs the agent on the distance to any obstacle (walls or other agents) it touches. In comparison, the camera is placed on the front of the robotic agent and is constituted of $12$ rays spread in a $90$ degrees cone. Each ray informs on the type (hunter, boar or stag) and proximity of the nearest agent in its direction. Each hunter begins the simulation next to the other agent at one side of the arena.

    In opposition to the predators, prey are static and stay at their initial position until either the end of the simulation or their capture by a hunter (experiments with moving prey capable of avoidance behaviours did not show significantly different results). For a prey to be successfully captured, a hunter needs to remain in contact of this prey for $800$ time steps (out of a total number of $20000$ simulation steps). The hunter is then rewarded with the value corresponding to the prey. The prey is finally removed from the environment and replaced at a random position in the arena. We thus ensure that both the number of prey and the ratio of the types of prey are kept constant. We consider that collective hunting happens when both hunters are in contact of the prey at the last time step of its capture. This implies that is not necessary for both agents to be in contact of the prey during all of the hunting time for cooperation to happen.

    Each hunter is controlled by a fully-connected multilayer perceptron with a single hidden layer. The inputs of this neural network are constituted of all the sensory information of the agent and a bias neuron whose value is always $1$. $1$ input neuron is used for each of the $12$ proximity sensors and $3$ neurons for each of the $12$ rays of the camera (the type of an agent is encoded by $2$ binary values and $1$ value is used to encode proximity). In consequence, the total number of input neurons amounts to $49$. The hidden layer is constituted of $8$ neurons while the output layer has $2$ neurons, each one of them encoding for the speed of each of the agent's wheels. While the connection weights of the network are evolved, the topology is kept identical. Finally, the mapping function used to compute the outputs is a sigmoid.


  \subsection*{Simulating Artificial Evolution}
    The genome has a varying size. Indeed, to simulate neuronal plasticity, each individual can evolve two topologically similar neural networks. At the start of evolution, genomes are initialized with $410$ real values sampled uniformly in the range \([0,1]\). This amounts to the number of connection weights of a single neural network. At each generation of the algorithm, a genome encoding for a single neural network has a probability of \(5 \times 10^{-2}\) to be duplicated. When a duplication event occurs, the genome then encodes separately for the two neural networks, which means that its size is $820$. Each generation, there is also a probability of \(5 \times 10^{-3}\) that a deletion event occurs for a genome which encodes for two neural networks. If this happens, one of the two neural networks encoded by this genome is randomly lost and the size of this genome is reverted back to $410$.

    Evolution is simulated by a classical evolutionary algorithm. At each generation of the algorithm, every individual is paired $5$ times with a randomly chosen partner (which may be different each time). Each of these pairs is then independently evaluated in the environment during $20000$ steps. In order to decrease the stochasticity effects occuring because of the random positioning of the prey, each pair is evaluated $5$ times. Hence $25$ simulations are performed for each individual. The fitness of an individual is then computed as the average reward obtained over these $25$ simulations.

    Selection is conducted according to a \((10 + 10)\) elitist selection strategy. More precisely, the population of the next generation is constituted of the $10$ best individuals of the previous generation and $10$ offsprings sampled from these $10$ best individuals. Each offspring is a mutated clone of its parent and no recombination is used. Mutations are sampled according to Gaussian operator, with a standard deviation of \(2 \times 10^{-1}\) and a per-gene mutation probability of \(5 \times 10^{-3}\). Finally, each experiment was conducted during $9000$ generations and replicated $30$ times.